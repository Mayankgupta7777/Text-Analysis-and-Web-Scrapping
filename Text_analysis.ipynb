{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm2J+n5G+7zBYKQzdX5JKR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayankgupta7777/Text-Analysis-and-Web-Scrapping/blob/main/Text_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install syllables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHV4pp39Te67",
        "outputId": "d44c2438-c4b9-44fd-86da-2b608f80e9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting syllables\n",
            "  Downloading syllables-1.0.9-py3-none-any.whl (15 kB)\n",
            "Collecting cmudict<2.0.0,>=1.0.11 (from syllables)\n",
            "  Downloading cmudict-1.0.16-py3-none-any.whl (939 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata<7.0,>=5.1 (from syllables)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict<2.0.0,>=1.0.11->syllables) (6.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=5.1->syllables) (3.17.0)\n",
            "Installing collected packages: importlib-metadata, cmudict, syllables\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed cmudict-1.0.16 importlib-metadata-6.11.0 syllables-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHNINvsqTqZT",
        "outputId": "dfa668b1-ad8b-4c5f-df6b-a98da200c58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHXJaFl12ilb",
        "outputId": "da316e14-5f08-4e28-f0e3-615f7c57cadf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Score: 82\n",
            "Negative Score: 39\n",
            "Polarity Score: 0.3553718978894885\n",
            "Subjectivity Score: 0.4040399385560676\n",
            "Average Sentence Length: 27.367088607594937\n",
            "Percentage of Complex Words: 23.21924144310823\n",
            "Fog Index: 20.234532020281268\n",
            "Average Number of Words per Sentence: 27.367088607594937\n",
            "Complex Word Count: 502\n",
            "Word Count: 2162\n",
            "Syllable per Word: 1.7641073080481036\n",
            "Count of Personal Pronouns: 65\n",
            "Average Word Length: 4.795097132284921\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import syllables\n",
        "\n",
        "# Step 1: Extracting text from the URL\n",
        "url = \"https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "article = soup.find('article')  # Adjust tag as needed\n",
        "text = article.get_text() if article else \"\"\n",
        "\n",
        "# Step 2: Textual analysis\n",
        "nltk.download('punkt')\n",
        "sentences = sent_tokenize(text)\n",
        "words = word_tokenize(text)\n",
        "tagged_words = nltk.pos_tag(words)\n",
        "syllable_count = sum(syllables.estimate(w) for w in words)\n",
        "complex_words = [word for word in words if syllables.estimate(word) > 2]\n",
        "personal_pronouns = [word for word, tag in tagged_words if tag in ['PRP', 'PRP$']]\n",
        "\n",
        "\n",
        "# Calculating various metrics\n",
        "positive_score = len([word for word in words if TextBlob(word).sentiment.polarity > 0])\n",
        "negative_score = len([word for word in words if TextBlob(word).sentiment.polarity < 0])\n",
        "polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)  # To avoid division by zero\n",
        "subjectivity_score = TextBlob(text).sentiment.subjectivity\n",
        "average_sentence_length = len(words) / len(sentences) if sentences else 0\n",
        "complex_word_list = [word for word in words if syllables.estimate(word) > 2]\n",
        "complex_word_count = len(complex_word_list)\n",
        "percentage_complex_words = (complex_word_count / len(words)) * 100 if words else 0\n",
        "fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
        "average_sentence_length = len(words) / len(sentences) if sentences else 0\n",
        "word_count = len(words)\n",
        "syllable_per_word = syllable_count / word_count if word_count > 0 else 0\n",
        "personal_pronouns_count = len(personal_pronouns)\n",
        "average_word_length = sum(len(word) for word in words) / word_count if word_count > 0 else 0\n",
        "\n",
        "\n",
        "# Step 3: Output Results\n",
        "print(\"Positive Score:\", positive_score)\n",
        "print(\"Negative Score:\", negative_score)\n",
        "print(\"Polarity Score:\", polarity_score)\n",
        "print(\"Subjectivity Score:\", subjectivity_score)\n",
        "print(\"Average Sentence Length:\", average_sentence_length)\n",
        "print(\"Percentage of Complex Words:\", percentage_complex_words)\n",
        "print(\"Fog Index:\", fog_index)\n",
        "print(\"Average Number of Words per Sentence:\", average_sentence_length)\n",
        "print(\"Complex Word Count:\", complex_word_count)\n",
        "print(\"Word Count:\", word_count)\n",
        "print(\"Syllable per Word:\", syllable_per_word)\n",
        "print(\"Count of Personal Pronouns:\", personal_pronouns_count)\n",
        "print(\"Average Word Length:\", average_word_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8zFZAmSv2omk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}